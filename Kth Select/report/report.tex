% Created 2024-01-13 Sat 19:03
% Intended LaTeX compiler: xelatex
\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage[margin=2cm]{geometry}
\input{~/.doom.d/fancyLatexTemplate.tex}
\author{Spyridon Baltsas - AEM: 10443}
\date{}
\title{Parallel and Distributed Systems - Kth Select Report}
\hypersetup{
 pdfauthor={Spyridon Baltsas - AEM: 10443},
 pdftitle={Parallel and Distributed Systems - Kth Select Report},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.2 (Org mode 9.6.1)}, 
 pdflang={English}}
\usepackage[style=ieee]{biblatex}
\addbibresource{/media/spyros/Data/sbalt/vs/Parallel and Distributed Systems/Kth Select/report/bibliography.bib}
\begin{document}

\maketitle

\section{Summary}
\label{sec:orga8d05a3}
This report is about my proposed solution for Kth Select problem. To be more specific, here are briefly presented and explained the algorithms I have implemented for my approach for both single process and multiple processes with distributed memory use cases. Additionally, the efficiency of MPI algorithm against various large datasets will be examined for different amount of processes, and MPI's effectiveness itself when it comes to distributing processes among several compute instances. The source code, building instructions and how to pass arguments to the compiled binary can be found \href{https://github.com/thetonk/pds-solutions/tree/main/Kth\%20Select}{\emph{in this repository}} and its \href{https://github.com/thetonk/pds-solutions/blob/main/Kth\%20Select/README.md}{\emph{README}}.

\section{Algorithm}
\label{sec:orgb59a8d7}
\subsection{The problem}
\label{sec:org599f0f9}
The problem is stated like this: ``In a vector of unsorted elements, find which element would be in the k-th position if the vector was sorted in ascending order''.
\subsection{Approach}
\label{sec:org3c01fd1}
\subsubsection{Sequential}
\label{sec:orge224e3d}
The most effective algorithm to address this problem is QuickSelect. QuickSelect is very similar to QuickSort. A pivot element is selected from the array, and after using the \texttt{partition} function. The Lomuto's partitioning scheme was selected for the sake of simplicity. As a result, array is splitted in two sub-arrays;
\begin{itemize}
\item A sub-array containing elements which are smaller or equal to the pivot.
\item A sub-array containing elements larger than pivot.
\end{itemize}
Here is the point where QuickSelect differs from QuickSort. Instead of recursing on both subarrays, we recurse on the subarray where the k-th is included. For example, if k is larger than the position of pivot, then we recurse to the sub-array containing the elements larger than pivot. Finally, the algorithm stops when k is equal to the position of pivot element. In that case, the problem is solved, we found the k-th smallest element.

It can be proven that the average time complexity is linear (\(\mathcal{O}(n)\)), and square (\(\mathcal{O}(n^{2})\)) in the worst case where the array is already sorted \autocite{quickselect}.
\subsubsection{Parallel / Distributed Memory}
\label{sec:orgced3155}
Since QuickSelect appears to be that fast when a single process is used, I attempted to create an implementation for distributed systems using the MPI library. In such a distributed memory environment, MPI is currently the only way to go. As a result, since shared memory between processes is completely absent, the task of implementing the quickselect algorithm in such a stable way may get very challenging for the following reasons;
\begin{itemize}
\item Starvation of root process. The process who controls the other processes (also known as the root process) by advertising the pivot, may run out of elements and therefore rely on the elements of the other processes to find the pivot element that should be picked correctly. As a result, there will be an overhead of processes communicating with each other, especially when processes are on different computers.
\item Some processes may have all of the elements in their subarrays either larger or smaller as pivot, and because of that they may be not able to contribute to speeding up the search for the k-th element any further.
\item Recursive nature of algorithm itself. There may be few extreme cases, sometimes very hard to predict, on which algorithm may fail to provide an answer, where either the answer will be incorrect or get stuck in an infinite loop. In addition, a recursive algorithm may not be able to get parallelized as efficiently as an imperative one could be.
\item MPI heavily relies on collective operations. All processes must finish on the same time and not earlier or later than each other. \autocite{mpi-forum}
\end{itemize}
\uline{DISCLAIMER:} As the README of my repository states, the MPI version may get stuck in an infinite loop for a few cases. The reason is currently unknown. In case it happens, please try changing the number of processes, since it has been observed that fixes the issue most of the times.

Taking the above points into consideration the QuickSelect was modified. The behavior of algorithm changes slightly whether process is the controlling one (root process) or not. The logic can be summed up in the following steps;
\begin{enumerate}
\item Root process selects a pivot. If it has elements left, the last element of array is selected. Otherwise it is depleted, the smallest element of the rest of processes is selected as the pivot. The root process announces the pivot to the rest of processes.
\item All processes split their arrays again in 2 subarrays with the same partitioning scheme as the sequential, one containing elements less or equal to pivot (left sub-array), and one containing elements larger than pivot (right sub-array).
\item The amount of elements that is smaller than pivot and the amount of elements that are equal to that are calculated, in order the global position (the position of pivot in the sequential QuickSelect) of pivot to be found. Let \(p\) be the global pivot position and \(d\) be the amount of elements equal to pivot. If \(k\) belongs to the \([p, p+d)\) set, then the value of k-th element is found. The algorithm stops.
\item Otherwise, the following actions are taken;
\begin{enumerate}
\item If \(k < p\);
\begin{enumerate}
\item If process is the root and all elements are larger than pivot, process is depleted. Otherwise, find the position of the last element smaller than pivot and recurse into the resulting sub-array.
\item If the process is not the root, and the global position is out of the bounds of the current array, it is considered depleted and recurses into the same array (idles). Otherwise, if the element at the global position is equal to pivot, recurse on the left sub-array, excluding the element equal to pivot. If less than pivot, then again recurse on the left sub-array but contain the element as well.
\end{enumerate}
\item If \(k > p\), then similarly;
\begin{enumerate}
\item If process is the root and all elements except pivot are less than it, process is depleted. Otherwise, find the position of the last element larger than pivot and recurse into the resulting sub-array.
\item If the process is not the root, and the global position is out of the bounds of the current array, it is considered depleted and recurses into the same array (idles). Otherwise, if the element at the global position is equal to pivot, recurse on the right sub-array, excluding the element equal to pivot. If larger than pivot, then again recurse on the right sub-array but contain the element as well.
\end{enumerate}
\end{enumerate}
\end{enumerate}
\pagebreak
\section{Test Specifications}
\label{sec:orgcbabfd9}
Please take note that on the following processing times the duration of the initial overhead was not taken into account. The following operations were considered as ``overhead'', as it may be seen from source code;
\begin{itemize}
\item I/O Operations. The file reading and downloading time, and printing download status to the \texttt{stdout}, since data fetching and no actual processing is taking place.
\item Data structures creation and population. In other words, the initial memory allocation and data loading into the array.
\item MPI initialization and preparation.
\end{itemize}
\subsection{System Specifications}
\label{sec:orgc231db1}
For the production of all the following results, Aristotle University of Thessaloniki (AUTh) High Performance Computing Infrastructure was used. The operating system in charge is CentOS. \autocite{hpc-resources}
\subsubsection{Sequential}
\label{sec:org3a76d4b}
Sequential jobs were submitted to the HPC's login nodes, since they had more than enough resources for this task. Their resources had the following specifications, processing power wise;
\begin{itemize}
\item 2 x AMD EPYC 7302 @ 3.00 GHz (16 cores, 32 threads)
\item 64 GB RAM
\end{itemize}
\subsubsection{Parallel / Distributed}
\label{sec:org0bac350}
Distributed jobs were submitted to the \emph{rome} partition of HPC, since it was proven ideal for parallel tasks. Its resources had the following specifications, processing power wise;
\begin{itemize}
\item AMD EPYC 7662 @ 2.00 GHz (64 cores, 128 threads) \autocite{hpc-resources}
\item At least 1.95 GB per CPU
\end{itemize}
\subsection{Test Dataset Specifications}
\label{sec:org97ea941}
\begin{center}
\begin{tabular}{llr}
\hline
Name & File Size & 32-bit Integer Count\\[0pt]
\hline
\href{https://dumps.wikimedia.org/other/static\_html\_dumps/current/el/wikipedia-el-html.tar.7z}{Greek Wiki Dump} & 107 MB & 28084359\\[0pt]
\href{https://developer.download.nvidia.com/compute/cuda/12.0.0/local\_installers/cuda\_12.0.0\_525.60.13\_linux.run}{NVIDIA CUDA 12 Linux Runfile} & 3.8 GB & 1030846977\\[0pt]
\hline
\end{tabular}
\end{center}
\pagebreak
\section{Results}
\label{sec:org8819300}
\subsection{Charts}
\label{sec:org646e005}
\subsubsection{Greek Wiki Dump}
\label{sec:orgf1c4792}
\begin{center}
\includegraphics[height=200]{./charts/greek-wiki-dump/processing-time-nodes.png}
\end{center}
\begin{center}
\includegraphics[height=200]{./charts/greek-wiki-dump/process-distribution-effectiveness.png}
\end{center}
\subsubsection{NVIDIA CUDA 12 Linux Runfile}
\label{sec:org2b236fe}
\begin{center}
\includegraphics[height=200]{./charts/cuda-12-runfile/processing-time-nodes.png}
\end{center}
\begin{center}
\includegraphics[height=200]{./charts/cuda-12-runfile/process-distribution-effectiveness.png}
\end{center}

\printbibliography
\end{document}